{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e48fff8989b4d93aebfe001713ebe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1dc5997a98b4ffca8acd8f1863fc130",
              "IPY_MODEL_84349134cac44ce9b489378b24cc9fa5",
              "IPY_MODEL_2838bd4532d74ec7b3d177a8e003a561"
            ],
            "layout": "IPY_MODEL_ec36e8f72fa14c86b5e5636d9ad31ecf"
          }
        },
        "a1dc5997a98b4ffca8acd8f1863fc130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd41585275844af8aa92c27afbbb11a5",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c6b70bb832489394454deca1aa51bd",
            "value": "epoch: 0/14:   1%"
          }
        },
        "84349134cac44ce9b489378b24cc9fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77dff0ec119d415a9525be9278b6d66c",
            "max": 4432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8059c4f097e94f73a20b108133e5ee1b",
            "value": 64
          }
        },
        "2838bd4532d74ec7b3d177a8e003a561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e63e09b85344a1db502e5e380a97c17",
            "placeholder": "​",
            "style": "IPY_MODEL_d7db7f2d3bbc4d848fb33bb96e4b4525",
            "value": " 64/4432 [03:07&lt;2:45:11,  2.27s/it, loss=0.008936]"
          }
        },
        "ec36e8f72fa14c86b5e5636d9ad31ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd41585275844af8aa92c27afbbb11a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c6b70bb832489394454deca1aa51bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77dff0ec119d415a9525be9278b6d66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8059c4f097e94f73a20b108133e5ee1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e63e09b85344a1db502e5e380a97c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7db7f2d3bbc4d848fb33bb96e4b4525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Enviorment\n"
      ],
      "metadata": {
        "id": "_KAzAvjKhwb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check out Colab Instance Region"
      ],
      "metadata": {
        "id": "CzeI3F9vjb40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipinfo.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7YxlFf-jXTb",
        "outputId": "7806762b-a828-44e1-beda-28bc35d666f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ip\": \"34.82.176.201\",\n",
            "  \"hostname\": \"201.176.82.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"The Dalles\",\n",
            "  \"region\": \"Oregon\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"45.5946,-121.1787\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"97058\",\n",
            "  \"timezone\": \"America/Los_Angeles\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intsall Essential Packaeges\n",
        "\n",
        "`super-image` library is built on top of **Hugging Face**'s `transformers` and `datasets`"
      ],
      "metadata": {
        "id": "53oNfTDU4aOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install super-image datasets transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFprZGbb4ak8",
        "outputId": "582e5e84-fbe1-401e-af23-b0ea16a51245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "XNClEaWBiATD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "\n",
        "\n",
        "from super_image import Trainer, PreTrainedModel, TrainingArguments\n",
        "from super_image.models import EdsrModel\n",
        "from super_image.trainer import Trainer, logger\n",
        "from super_image.utils.metrics import AverageMeter"
      ],
      "metadata": {
        "id": "qpjGAr7whwyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4u4KLpJbuw7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paths and Directories"
      ],
      "metadata": {
        "id": "y80KYwyIiJdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFoBo8t5iKS1",
        "outputId": "377f6414-7801-4ed3-fee0-88cc0f0ba648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'Colab Notebooks'   Education\t        IFTTT   Neuromarketing-EHIA\n",
            " datasets\t   'Google AI Studio'   manga\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = Path('/content/drive/MyDrive/datasets/sen2venus')\n",
        "\n",
        "TACO_RAW_DIR = ROOT_PATH / 'TACO_raw_data'\n",
        "os.makedirs(TACO_RAW_DIR, exist_ok=True)\n",
        "print(f\"Data will be saved to: {TACO_RAW_DIR}\")\n",
        "\n",
        "SELECTED_SUBSETS = [\n",
        "    \"SUDOUE-4\",\n",
        "    \"SUDOUE-5\",\n",
        "    \"SUDOUE-6\"\n",
        "]\n",
        "TACO_FILE_PATHS = [TACO_RAW_DIR / f\"{site_name}.taco\" for site_name in SELECTED_SUBSETS]\n",
        "\n",
        "\n",
        "NORMALIZED_SETS_DIR = ROOT_PATH / 'normalized_sets'\n",
        "os.makedirs(NORMALIZED_SETS_DIR, exist_ok=True)\n",
        "print(f\"Normalaized datest will be saved to:\\n\\t {NORMALIZED_SETS_DIR}\")\n",
        "\n",
        "TRAIN_SAVE_DIR = NORMALIZED_SETS_DIR / 'train'\n",
        "os.makedirs(TRAIN_SAVE_DIR, exist_ok=True)\n",
        "print(f\"Train data will be saved to:\\n\\t {TRAIN_SAVE_DIR}\")\n",
        "\n",
        "VAL_SAVE_DIR = NORMALIZED_SETS_DIR / 'val'\n",
        "os.makedirs(VAL_SAVE_DIR, exist_ok=True)\n",
        "print(f\"Validation data will be saved to:\\n\\t {VAL_SAVE_DIR}\")\n",
        "\n",
        "TEST_SAVE_DIR = NORMALIZED_SETS_DIR / 'test'\n",
        "os.makedirs(TEST_SAVE_DIR, exist_ok=True)\n",
        "print(f\"Test data will be saved to:\\n\\t {TEST_SAVE_DIR}\")\n",
        "\n",
        "# essential for resuming training and saving final model.\n",
        "FINETUNR_SAVE_DIR = ROOT_PATH / 'edsr_finetune'\n",
        "os.makedirs(FINETUNR_SAVE_DIR, exist_ok=True)\n",
        "print(f\"Finetuning data including checkpoints and logs will be saved to:\\n\\t{FINETUNR_SAVE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-EoaWOvpdsx",
        "outputId": "4627758f-ce53-4e2a-c1b8-4ef9bb9c9281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data will be saved to: /content/drive/MyDrive/datasets/sen2venus/TACO_raw_data\n",
            "Normalaized datest will be saved to:\n",
            "\t /content/drive/MyDrive/datasets/sen2venus/normalized_sets\n",
            "Train data will be saved to:\n",
            "\t /content/drive/MyDrive/datasets/sen2venus/normalized_sets/train\n",
            "Validation data will be saved to:\n",
            "\t /content/drive/MyDrive/datasets/sen2venus/normalized_sets/val\n",
            "Test data will be saved to:\n",
            "\t /content/drive/MyDrive/datasets/sen2venus/normalized_sets/test\n",
            "Finetuning data including checkpoints and logs will be saved to:\n",
            "\t/content/drive/MyDrive/datasets/sen2venus/edsr_finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Define PyTorch Datasets & Dataloaders"
      ],
      "metadata": {
        "id": "ClVyKPm_peAg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vV2B_ZtT6oW"
      },
      "outputs": [],
      "source": [
        "class PreNormalizedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Efficiently reads pre-processed, sharded tensor files from disk.\n",
        "    \"\"\"\n",
        "    def __init__(self, shard_dir: Union[str, Path]):\n",
        "        self.shard_dir = Path(shard_dir)\n",
        "        self.shard_paths: List[Path] = sorted(self.shard_dir.glob(\"*.pt\"))\n",
        "\n",
        "        if not self.shard_paths:\n",
        "            raise ValueError(f\"No shard files ('*.pt') found in {self.shard_dir}\")\n",
        "\n",
        "        # To calculate length, we check the size of the first shard and assume\n",
        "        # all but the last are the same size.\n",
        "        first_shard = torch.load(self.shard_paths[0])\n",
        "        self.shard_size = len(first_shard)\n",
        "        last_shard = torch.load(self.shard_paths[-1])\n",
        "        self.length = (len(self.shard_paths) - 1) * self.shard_size + len(last_shard)\n",
        "\n",
        "        # Simple cache to avoid re-loading the same shard consecutively\n",
        "        self._cache = {}\n",
        "        self._cached_shard_index = -1\n",
        "        print(f\"Initialized dataset from {self.shard_dir} with {self.length} samples across {len(self.shard_paths)} shards.\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx)->Dict[str, np.ndarray]:\n",
        "        shard_index = idx // self.shard_size\n",
        "        index_in_shard = idx % self.shard_size\n",
        "\n",
        "        if shard_index != self._cached_shard_index:\n",
        "            self._cache = torch.load(self.shard_paths[shard_index])\n",
        "            self._cached_shard_index = shard_index\n",
        "\n",
        "        # coupled with TACORGBDataset dataset class\n",
        "        # each item in the shard is a squeezed dictionary with keys lr and hr\n",
        "        squeezed_sample = self._cache[index_in_shard]\n",
        "        return squeezed_sample['lr'], squeezed_sample['hr']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader Instantiation"
      ],
      "metadata": {
        "id": "Iw7l7AuU5IUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PreNormalizedDataset(TRAIN_SAVE_DIR)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TINjQ7ZN5MZf",
        "outputId": "1a7ddca9-8ccb-40d3-a190-f13e5592dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized dataset from /content/drive/MyDrive/datasets/sen2venus/normalized_sets/train with 4436 samples across 5 shards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Verifying  dataset output format:\")\n",
        "sample_output = train_dataset[0]\n",
        "print(sample_output.keys())\n",
        "print(\"LR shape:\", sample_output['pixel_values'].shape)\n",
        "print(\"HR shape:\", sample_output['labels'].shape)\n",
        "\n",
        "\n",
        "print(\"---Verifying  batch shape:\")\n",
        "\n",
        "lr_batch, hr_batch = next(iter(train_loader))\n",
        "\n",
        "print(f\"Verification successful!\")\n",
        "print(f\"LR batch shape: {lr_batch.shape}\")\n",
        "print(f\"HR batch shape: {hr_batch.shape}\")\n",
        "print(f\"LR batch dtype: {lr_batch.dtype}\")\n",
        "print(f\"HR batch dtype: {hr_batch.dtype}\")"
      ],
      "metadata": {
        "id": "PI4v6MuK5mgG",
        "outputId": "db98c11b-e600-4f83-af17-060afa7af788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Verifying  dataset output format:\n",
            "dict_keys(['pixel_values', 'labels'])\n",
            "LR shape: torch.Size([3, 128, 128])\n",
            "HR shape: torch.Size([3, 256, 256])\n",
            "---Verifying  batch shape:\n",
            "Verification successful!\n",
            "LR batch shape: torch.Size([16, 3, 128, 128])\n",
            "HR batch shape: torch.Size([16, 3, 256, 256])\n",
            "LR batch dtype: torch.float32\n",
            "HR batch dtype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = PreNormalizedDataset(VAL_SAVE_DIR)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "2-xBNDU35Tcg",
        "outputId": "710876e9-f804-438e-bf70-df1dc5104d1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized dataset from /content/drive/MyDrive/datasets/sen2venus/normalized_sets/val with 554 samples across 1 shards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = PreNormalizedDataset(TEST_SAVE_DIR)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfwFUqvdvWSQ",
        "outputId": "114f2261-37e8-4d98-d5b6-a8d17033fa29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized dataset from /content/drive/MyDrive/datasets/sen2venus/normalized_sets/test with 556 samples across 1 shards.\n",
            "Loaded 556 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load the Pre-trained EDSR Model"
      ],
      "metadata": {
        "id": "YUwwsMCp7JIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectives**:\n",
        "\n",
        "\n",
        "\n",
        "1.   Loading a well-known, **pre-trained** architecture (edsr-base) specifically configured for **2x super-resolution**.\n",
        "2.   Confirming that the model accepts data batches and produces outputs of the correct shape ([16, 3, 256, 256])."
      ],
      "metadata": {
        "id": "B92rUzqB_F-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Instantiate and Inspect the pre-trained EDSR model"
      ],
      "metadata": {
        "id": "DSU_eKfZ8RUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'from_pretrained' method downloads the model configuration and weights.\n",
        "# We must specify our desired scale factor.\n",
        "# (LR: 128x128, HR: 256x256), -> scale is 2.\n",
        "scale = 2\n",
        "model_id = 'eugenesiow/edsr-base'\n",
        "model = EdsrModel.from_pretrained(model_id, scale=scale)\n",
        "\n",
        "# Inspect the model architecture\n",
        "print(\"Model architecture loaded successfully:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d8c5mkF7jh0",
        "outputId": "e72fb14e-e4a6-4234-e803-8720add8f912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_2x.pt\n",
            "Model architecture loaded successfully:\n",
            "DataParallel(\n",
            "  (module): EdsrModel(\n",
            "    (sub_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (add_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (head): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (body): Sequential(\n",
            "      (0): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (11): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (12): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (13): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (14): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (15): ResBlock(\n",
            "        (body): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (tail): Sequential(\n",
            "      (0): Upsampler(\n",
            "        (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): PixelShuffle(upscale_factor=2)\n",
            "      )\n",
            "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Sanity Check: Pass one batch of data through the model"
      ],
      "metadata": {
        "id": "z-QbcXpS8ae2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a crucial test to ensure the input/output dimensions are compatible.\n",
        "print(\"\\nPerforming a forward pass sanity check...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode for this check\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Get a single batch from our dataloader\n",
        "    lr_batch, hr_batch = next(iter(train_loader))\n",
        "\n",
        "    # Move the batch to the same device as the model\n",
        "    lr_batch = lr_batch.to(device)\n",
        "\n",
        "    # Perform a forward pass\n",
        "    predictions = model(lr_batch)\n",
        "\n",
        "    print(f\"Sanity check successful!\")\n",
        "    print(f\"Running on device: {device}\")\n",
        "    print(f\"Model Input Shape (LR): {lr_batch.shape}\")\n",
        "    print(f\"Model Output Shape (Predictions): {predictions.shape}\")\n",
        "    print(f\"Target Shape (HR): {hr_batch.shape}\")\n",
        "\n",
        "# Compare output shape with the target High-Resolution shape\n",
        "assert predictions.shape == hr_batch.shape, \"Model output shape does not match target HR shape!\"\n",
        "print(\"Output shape matches target shape. Ready for training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgnXeFZE8QJQ",
        "outputId": "239c1b51-033c-4623-9249-141a43c60d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing a forward pass sanity check...\n",
            "Sanity check successful!\n",
            "Running on device: cuda\n",
            "Model Input Shape (LR): torch.Size([16, 3, 128, 128])\n",
            "Model Output Shape (Predictions): torch.Size([16, 3, 256, 256])\n",
            "Target Shape (HR): torch.Size([16, 3, 256, 256])\n",
            "Output shape matches target shape. Ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Configure and Launch the Trainer"
      ],
      "metadata": {
        "id": "csIBPYQpNALf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custum Trainer with Checkpoints"
      ],
      "metadata": {
        "id": "8NRbqBcmcRXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class CustomResumableTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.optimizer = None\n",
        "        self.scheduler = None\n",
        "\n",
        "    def save_checkpoint(self, epoch):\n",
        "        \"\"\"Saves a complete training state checkpoint.\"\"\"\n",
        "        output_dir = self.args.output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        checkpoint_path = os.path.join(output_dir, 'training_checkpoint.pt')\n",
        "\n",
        "        if self.optimizer is None or self.scheduler is None:\n",
        "            logger.warning(\"Optimizer/Scheduler not initialized. Cannot save full checkpoint.\")\n",
        "            return\n",
        "\n",
        "        state = {\n",
        "            'epoch': epoch, 'best_metric': self.best_metric,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "        }\n",
        "        torch.save(state, checkpoint_path)\n",
        "        logger.info(f\"Saved complete training checkpoint to {checkpoint_path}\")\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        \"\"\"Loads a complete training state from a checkpoint.\"\"\"\n",
        "        checkpoint_path = os.path.join(self.args.output_dir, 'training_checkpoint.pt')\n",
        "        start_epoch = 0\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            logger.warning(\"No training checkpoint found. Starting from scratch.\")\n",
        "            return start_epoch\n",
        "        try:\n",
        "            state = torch.load(checkpoint_path, map_location=self.args.device)\n",
        "            self.model.load_state_dict(state['model_state_dict'])\n",
        "            if self.optimizer is None: self._create_optimizer_and_scheduler()\n",
        "            self.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "            self.scheduler.load_state_dict(state['scheduler_state_dict'])\n",
        "            self.best_metric = state.get('best_metric', 0.0)\n",
        "            start_epoch = state['epoch'] + 1\n",
        "            logger.info(f\"Successfully loaded checkpoint. Resuming from epoch {start_epoch}.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load checkpoint: {e}. Starting from scratch.\")\n",
        "            start_epoch = 0\n",
        "        return start_epoch\n",
        "\n",
        "    def _create_optimizer_and_scheduler(self):\n",
        "        \"\"\"Helper function to initialize optimizer and scheduler.\"\"\"\n",
        "        self.optimizer = Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
        "        step_size = int(len(self.train_dataset) / self.args.train_batch_size * 200)\n",
        "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=step_size, gamma=self.args.gamma)\n",
        "\n",
        "    def train(self, **kwargs):\n",
        "        \"\"\"Complete, resumable training loop.\"\"\"\n",
        "        self._create_optimizer_and_scheduler()\n",
        "        start_epoch = self.load_checkpoint()\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "\n",
        "        for epoch in range(start_epoch, self.args.num_train_epochs):\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = self.args.learning_rate * (0.1 ** (epoch // int(self.args.num_train_epochs * 0.8)))\n",
        "\n",
        "            self.model.train()\n",
        "            epoch_losses = AverageMeter()\n",
        "            with tqdm(total=(len(self.train_dataset) - len(self.train_dataset) % self.args.train_batch_size)) as t:\n",
        "                t.set_description(f'epoch: {epoch}/{self.args.num_train_epochs - 1}')\n",
        "                for data in train_dataloader:\n",
        "                    inputs, labels = data\n",
        "                    inputs = inputs.to(self.args.device)\n",
        "                    labels = labels.to(self.args.device)\n",
        "                    preds = self.model(inputs)\n",
        "                    loss = torch.nn.L1Loss()(preds, labels)\n",
        "                    epoch_losses.update(loss.item(), len(inputs))\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    self.scheduler.step()\n",
        "                    t.set_postfix(loss=f'{epoch_losses.avg:.6f}')\n",
        "                    t.update(len(inputs))\n",
        "\n",
        "            # --- Integrated Eval and Saving ---\n",
        "            # Call original eval logic, which updates self.best_epoch and self.best_metric\n",
        "            super().eval(epoch)\n",
        "            # If the eval run was the best so far, save full state\n",
        "            if self.best_epoch == epoch:\n",
        "                print(f\"New best model found at epoch {epoch}. Saving full checkpoint.\")\n",
        "                self.save_checkpoint(epoch)"
      ],
      "metadata": {
        "id": "9NDhC3KCcHfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer Config"
      ],
      "metadata": {
        "id": "5d8uiyuW4UWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DEFINITIVE Training Arguments based on a full-code review\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=FINETUNR_SAVE_DIR,\n",
        "\n",
        "    # --- Core parameters that are fully functional ---\n",
        "    num_train_epochs=15,          # Controls training length and the hardcoded LR decay\n",
        "    learning_rate=1e-4,           # Sets the initial learning rate\n",
        "    per_device_train_batch_size=16, # Controls training batch size\n",
        "\n",
        "    # --- Technical parameters that are functional ---\n",
        "    seed=42,                      # For reproducibility\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_num_workers=2,\n",
        ")"
      ],
      "metadata": {
        "id": "L3mw9OL7iOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Training"
      ],
      "metadata": {
        "id": "NDzl-_Nz4g5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = CustomResumableTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "Du4n51ivdOjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Training with full confidence in the underlying process.\n",
        "print(\"Starting model fine-tuning \")\n",
        "trainer.train()\n",
        "\n",
        "print(f\"\\nTraining complete. The best model was found at epoch {trainer.best_epoch} \"\n",
        "      f\"with a PSNR of {trainer.best_metric:.2f}.\")\n",
        "print(f\"The best model has been saved in: {output_dir}\")"
      ],
      "metadata": {
        "id": "fKxQxP2f4Nsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6e48fff8989b4d93aebfe001713ebe85",
            "a1dc5997a98b4ffca8acd8f1863fc130",
            "84349134cac44ce9b489378b24cc9fa5",
            "2838bd4532d74ec7b3d177a8e003a561",
            "ec36e8f72fa14c86b5e5636d9ad31ecf",
            "bd41585275844af8aa92c27afbbb11a5",
            "c9c6b70bb832489394454deca1aa51bd",
            "77dff0ec119d415a9525be9278b6d66c",
            "8059c4f097e94f73a20b108133e5ee1b",
            "8e63e09b85344a1db502e5e380a97c17",
            "d7db7f2d3bbc4d848fb33bb96e4b4525"
          ]
        },
        "outputId": "f20cfbf0-89f3-48db-9771-3ec55f53dbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model fine-tuning \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4432 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e48fff8989b4d93aebfe001713ebe85"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}