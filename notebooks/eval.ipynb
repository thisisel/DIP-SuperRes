{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "35d15c28",
      "metadata": {
        "id": "35d15c28"
      },
      "source": [
        "# Env Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223c6ad6",
      "metadata": {
        "id": "223c6ad6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "af15b487",
      "metadata": {
        "id": "af15b487",
        "outputId": "5c75561f-0076-45b5-ca48-c924bb8e6e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 14 11:11:36 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7455b23",
      "metadata": {
        "id": "b7455b23"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "322f033f",
      "metadata": {
        "id": "322f033f"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import List, Literal, Union, Dict\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "EnvModeType = Literal[\"colab\", \"remote\", \"local\"]\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Config:\n",
        "    env_mode: EnvModeType\n",
        "    selected_subsets: List[str] = field(\n",
        "        default_factory=lambda: [\"SUDOKU_4\", \"SUDOKU_5\", \"SUDOKU_6\"]\n",
        "    )\n",
        "\n",
        "    # Derived fields (init=False)\n",
        "    data_root: Path = field(init=False)\n",
        "    base_dir: Path = field(init=False)\n",
        "    taco_raw_dir: Path = field(init=False)\n",
        "    taco_file_paths: List[Path] = field(init=False)\n",
        "    normalized_sets_dir: Path = field(init=False)\n",
        "    finetune_dir: Path = field(init=False)\n",
        "    train_dir: Path = field(init=False)\n",
        "    val_dir: Path = field(init=False)\n",
        "    test_dir: Path = field(init=False)\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        # Set data_root based on env_mode (defaults; override in factory if needed)\n",
        "        data_root_map = {\n",
        "            # \"local\": Path.home() / \"mnt/shared\",\n",
        "            \"local\": Path(\"/mnt/shared\"),\n",
        "            # \"remote\": Path(\"/mnt/data\"),\n",
        "            \"remote\": Path.home(),\n",
        "            \"colab\": Path(\"/content/drive/MyDrive\"),\n",
        "        }\n",
        "        object.__setattr__(\n",
        "            self, \"data_root\", data_root_map.get(self.env_mode, Path.cwd())\n",
        "        )\n",
        "\n",
        "        # Derive other paths\n",
        "        object.__setattr__(\n",
        "            self, \"base_dir\", self.data_root / \"datasets/sen2venus\"\n",
        "        )\n",
        "        # object.__setattr__(self, \"taco_raw_dir\", self.base_dir / \"TACO_raw_data\")\n",
        "        # object.__setattr__(\n",
        "        #     self,\n",
        "        #     \"taco_file_paths\",\n",
        "        #     [self.taco_raw_dir / f\"{subset}.taco\" for subset in self.selected_subsets],\n",
        "        # )\n",
        "        object.__setattr__(\n",
        "            self, \"normalized_sets_dir\", self.base_dir / \"normalized_sets\"\n",
        "        )\n",
        "        object.__setattr__(self, \"finetune_dir\", self.base_dir / \"finetune\")\n",
        "        object.__setattr__(self, \"train_dir\", self.normalized_sets_dir / \"train\")\n",
        "        object.__setattr__(self, \"val_dir\", self.normalized_sets_dir / \"val\")\n",
        "        object.__setattr__(self, \"test_dir\", self.normalized_sets_dir / \"test\")\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate config paths exist; raise errors otherwise.\"\"\"\n",
        "        missing_paths = []\n",
        "        for attr in [\n",
        "            \"data_root\",\n",
        "            \"base_dir\",\n",
        "            # \"taco_raw_dir\",\n",
        "            \"normalized_sets_dir\",\n",
        "            \"finetune_dir\",\n",
        "            \"train_dir\",\n",
        "            \"val_dir\",\n",
        "            \"test_dir\",\n",
        "        ]:\n",
        "            path: Path = getattr(self, attr)\n",
        "            if not path.exists():\n",
        "                missing_paths.append(str(path))\n",
        "        if missing_paths:\n",
        "            raise ValueError(f\"Missing paths: {', '.join(missing_paths)}\")\n",
        "        # for file_path in self.taco_file_paths:\n",
        "        #     if not file_path.exists():\n",
        "        #         missing_paths.append(str(file_path))\n",
        "        if missing_paths:\n",
        "            raise ValueError(f\"Missing taco files: {', '.join(missing_paths)}\")\n",
        "\n",
        "\n",
        "def setup_environment(env_mode: EnvModeType) -> None:\n",
        "    \"\"\"Perform environment-specific setup (side effects isolated here).\"\"\"\n",
        "    if env_mode == \"colab\":\n",
        "        try:\n",
        "            import super_image\n",
        "        except ImportError:\n",
        "            print(\"Installing 'super-image'...\")\n",
        "            try:\n",
        "                subprocess.run([\"pip\", \"install\", \"--quiet\", \"super-image\"], check=True)\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                raise RuntimeError(f\"Failed to install super-image: {e}\")\n",
        "\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "\n",
        "            drive.mount(\"/content/drive\", force_remount=True)\n",
        "        except ImportError:\n",
        "            raise RuntimeError(\"Google Colab module not found. Are you in Colab?\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to mount Google Drive: {e}\")\n",
        "\n",
        "        # Optional: Copy data to local /content for faster I/O in Colab\n",
        "        colab_vm_dir = Path(\"/content/taco_normalized\")\n",
        "        if not colab_vm_dir.exists():\n",
        "            print(\"Copying normalized data to local Colab storage for performance...\")\n",
        "            shutil.copytree(\n",
        "                Path(\n",
        "                    \"/content/drive/MyDrive/datasets/sen2venus/normalized_sets\"\n",
        "                ),\n",
        "                colab_vm_dir,\n",
        "            )\n",
        "            print(\"Copy complete.\")\n",
        "        # Avoid os.chdir; let users handle working dir if needed\n",
        "\n",
        "    elif env_mode == \"remote\":\n",
        "        print(\"Remote environment detected. No specific setup needed.\")\n",
        "\n",
        "    elif env_mode == \"local\":\n",
        "        print(\"Local environment detected. Ensuring dependencies...\")\n",
        "\n",
        "\n",
        "def create_config(env_mode: EnvModeType | None = None) -> Config:\n",
        "    \"\"\"Factory to create and setup config based on detected environment.\"\"\"\n",
        "    if env_mode is None:\n",
        "        if \"google.colab\" in sys.modules:\n",
        "            env_mode = \"colab\"\n",
        "        elif \"REMOTE_ENV_VAR\" in os.environ:\n",
        "            env_mode = \"remote\"\n",
        "        else:\n",
        "            env_mode = \"local\"\n",
        "\n",
        "    setup_environment(env_mode)\n",
        "    config = Config(env_mode=env_mode)\n",
        "    config.validate()\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "003e8698",
      "metadata": {
        "id": "003e8698",
        "outputId": "cc9c12b6-d743-4f90-f311-531733d64f7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing 'super-image'...\n",
            "Mounted at /content/drive\n",
            "Copying normalized data to local Colab storage for performance...\n",
            "Copy complete.\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "config = create_config('colab')\n",
        "print(config.data_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06da0aa8",
      "metadata": {
        "id": "06da0aa8"
      },
      "source": [
        "## Project imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4478ee67",
      "metadata": {
        "id": "4478ee67"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from super_image import Trainer, PreTrainedModel, TrainingArguments\n",
        "from super_image.models import EdsrModel\n",
        "from super_image.trainer import Trainer, logger\n",
        "from super_image.utils.metrics import AverageMeter, compute_metrics\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3d0056",
      "metadata": {
        "id": "7c3d0056"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a96cab0c",
      "metadata": {
        "id": "a96cab0c"
      },
      "outputs": [],
      "source": [
        "class PreNormalizedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Efficiently reads pre-processed, sharded tensor files from disk.\n",
        "    \"\"\"\n",
        "    def __init__(self, shard_dir: Union[str, Path]):\n",
        "        self.shard_dir = Path(shard_dir)\n",
        "        self.shard_paths: List[Path] = sorted(self.shard_dir.glob(\"*.pt\"))\n",
        "\n",
        "        if not self.shard_paths:\n",
        "            raise ValueError(f\"No shard files ('*.pt') found in {self.shard_dir}\")\n",
        "\n",
        "        # To calculate length, we check the size of the first shard and assume\n",
        "        # all but the last are the same size.\n",
        "        first_shard = torch.load(self.shard_paths[0])\n",
        "        self.shard_size = len(first_shard)\n",
        "        last_shard = torch.load(self.shard_paths[-1])\n",
        "        self.length = (len(self.shard_paths) - 1) * self.shard_size + len(last_shard)\n",
        "\n",
        "        # Simple cache to avoid re-loading the same shard consecutively\n",
        "        self._cache = {}\n",
        "        self._cached_shard_index = -1\n",
        "        print(f\"Initialized dataset from {self.shard_dir} with {self.length} samples across {len(self.shard_paths)} shards.\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx)->Dict[str, np.ndarray]:\n",
        "        shard_index = idx // self.shard_size\n",
        "        index_in_shard = idx % self.shard_size\n",
        "\n",
        "        if shard_index != self._cached_shard_index:\n",
        "            self._cache = torch.load(self.shard_paths[shard_index])\n",
        "            self._cached_shard_index = shard_index\n",
        "\n",
        "        # coupled with TACORGBDataset dataset class\n",
        "        # each item in the shard is a squeezed dictionary with keys lr and hr\n",
        "        squeezed_sample = self._cache[index_in_shard]\n",
        "        return squeezed_sample['lr'], squeezed_sample['hr']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0151e3b5",
      "metadata": {
        "id": "0151e3b5"
      },
      "source": [
        "# Step 1: Quantitative Evaluation on the Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb66367",
      "metadata": {
        "id": "ffb66367"
      },
      "source": [
        "### 1.1 Load the Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6cb826e2",
      "metadata": {
        "id": "6cb826e2",
        "outputId": "8c1e04ca-dc5d-4ad9-c676-f3a198a0eafd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_2x.pt\n",
            "Loading best model checkpoint from: /content/drive/MyDrive/datasets/sen2venus/finetune/edsr_base/best_model_checkpoint.pt\n",
            "Model and checkpoint states match. Loading directly.\n",
            "\n",
            "✅Successfully loaded model from epoch 14 with best validation PSNR 47.3143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): EdsrModel(\n",
              "    (sub_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (add_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (head): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (body): Sequential(\n",
              "      (0): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (2): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (3): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (4): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (5): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (6): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (7): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (8): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (9): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (10): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (11): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (12): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (13): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (14): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (15): ResBlock(\n",
              "        (body): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (tail): Sequential(\n",
              "      (0): Upsampler(\n",
              "        (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "test_data_dir = config.test_dir\n",
        "checkpoint_path = config.finetune_dir / 'edsr_base/best_model_checkpoint.pt'\n",
        "\n",
        "\n",
        "model = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=2)\n",
        "\n",
        "# If multiple GPUs are available, wrap the model in DataParallel\n",
        "# This ensures the model's structure matches the training environment.\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(f\"Using {torch.cuda.device_count()} GPUs. Wrapping model in DataParallel.\")\n",
        "  model = torch.nn.DataParallel(model)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# load the state dictionary from best checkpoint\n",
        "print(f\"Loading best model checkpoint from: {checkpoint_path}\")\n",
        "try:\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model_state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "    # --- Logic to handle all DataParallel cases ---\n",
        "    is_model_parallel = isinstance(model, torch.nn.DataParallel)\n",
        "    is_checkpoint_parallel = list(model_state_dict.keys())[0].startswith('module.')\n",
        "\n",
        "    final_state_dict = OrderedDict()\n",
        "\n",
        "    if is_model_parallel and not is_checkpoint_parallel:\n",
        "        # If the current model is parallel but the checkpoint isn't, add \"module.\" prefix\n",
        "        print(\"Model is parallel, checkpoint is not. Adding 'module.' prefix to keys...\")\n",
        "        for k, v in model_state_dict.items():\n",
        "            final_state_dict['module.' + k] = v\n",
        "    elif not is_model_parallel and is_checkpoint_parallel:\n",
        "        # If the checkpoint is parallel but the current model isn't, strip \"module.\" prefix\n",
        "        print(\"Checkpoint is parallel, model is not. Stripping 'module.' prefix from keys...\")\n",
        "        for k, v in model_state_dict.items():\n",
        "            final_state_dict[k[7:]] = v # k[7:] removes 'module.'\n",
        "    else:\n",
        "        # If they are both parallel or both not parallel, the keys match already.\n",
        "        print(\"Model and checkpoint states match. Loading directly.\")\n",
        "        final_state_dict = model_state_dict\n",
        "\n",
        "    # Load the correctly formatted state dictionary\n",
        "    model.load_state_dict(final_state_dict)\n",
        "\n",
        "    print(f\"\\n✅Successfully loaded model from epoch {checkpoint['epoch']} with best validation PSNR {checkpoint['best_metric']:.4f}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ ERROR: Checkpoint file not found at '{checkpoint_path}'. Please verify the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: An error occurred while loading the checkpoint: {e}\")\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba63ac97",
      "metadata": {
        "id": "ba63ac97"
      },
      "source": [
        "### 1.2 Prepare the Test DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d87beebc",
      "metadata": {
        "id": "d87beebc",
        "outputId": "fb20bf40-d018-4d7e-84f6-c8f18a1a169d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized dataset from /content/taco_normalized/test with 556 samples across 1 shards.\n",
            "Loaded test dataset with 556 samples.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    test_data_dir = Path(\"/content/taco_normalized/test\") if config.env_mode == \"colab\" else config.test_dir\n",
        "\n",
        "    test_dataset = PreNormalizedDataset(test_data_dir)\n",
        "    # For evaluation, batch size is typically 1 to measure per-image metrics.\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
        "    print(f\"Loaded test dataset with {len(test_dataset)} samples.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Failed to load the test dataset from '{test_data_dir}': {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Run Evaluation Loop and Report"
      ],
      "metadata": {
        "id": "_0DTxqmFhExK"
      },
      "id": "_0DTxqmFhExK"
    },
    {
      "cell_type": "code",
      "source": [
        "from super_image.data import EvalMetrics\n",
        "\n",
        "EvalMetrics().evaluate(model, test_dataset)\n",
        "print(f\"Total images evaluated: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "tvSB3L9MfjeD",
        "outputId": "5ce92dc5-a831-4b38-d4e5-3726fd8ecad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "36b8aff2d3364a8b980320473941934e",
            "45063bc480b3426888448cc72e2b9f78",
            "d6446c092e604062bed0f5bbf36b7a45",
            "873ef875dda64d59bf573dc86a9e15fb",
            "ad03ff526df44fbbb1f86d218ea8a23b",
            "244f16c4ef4f499191e98e7da7882679",
            "58b6e7550444403faac20f79c6999c79",
            "f3d24853661c4ed8b9f9ae7615c28ed9",
            "16bcbd1f7f4447cc859259272386cd21",
            "56cacc73503f4f2c8b675498ef4cb74c",
            "ccad6b42cb17490ba52b072fac7ffad5"
          ]
        }
      },
      "id": "tvSB3L9MfjeD",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating dataset:   0%|          | 0/556 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36b8aff2d3364a8b980320473941934e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scale:2      eval psnr: 47.46     ssim: 0.9910\n",
            "Total images evaluated: 556\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36b8aff2d3364a8b980320473941934e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45063bc480b3426888448cc72e2b9f78",
              "IPY_MODEL_d6446c092e604062bed0f5bbf36b7a45",
              "IPY_MODEL_873ef875dda64d59bf573dc86a9e15fb"
            ],
            "layout": "IPY_MODEL_ad03ff526df44fbbb1f86d218ea8a23b"
          }
        },
        "45063bc480b3426888448cc72e2b9f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244f16c4ef4f499191e98e7da7882679",
            "placeholder": "​",
            "style": "IPY_MODEL_58b6e7550444403faac20f79c6999c79",
            "value": "Evaluating dataset: 100%"
          }
        },
        "d6446c092e604062bed0f5bbf36b7a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d24853661c4ed8b9f9ae7615c28ed9",
            "max": 556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16bcbd1f7f4447cc859259272386cd21",
            "value": 556
          }
        },
        "873ef875dda64d59bf573dc86a9e15fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56cacc73503f4f2c8b675498ef4cb74c",
            "placeholder": "​",
            "style": "IPY_MODEL_ccad6b42cb17490ba52b072fac7ffad5",
            "value": " 556/556 [00:28&lt;00:00, 15.88it/s]"
          }
        },
        "ad03ff526df44fbbb1f86d218ea8a23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244f16c4ef4f499191e98e7da7882679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b6e7550444403faac20f79c6999c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3d24853661c4ed8b9f9ae7615c28ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bcbd1f7f4447cc859259272386cd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56cacc73503f4f2c8b675498ef4cb74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccad6b42cb17490ba52b072fac7ffad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}