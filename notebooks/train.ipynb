{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6e56bc",
   "metadata": {},
   "source": [
    "# Env Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d47f7",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10764955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Union, Dict\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "EnvModeType = Literal[\"colab\", \"remote\", \"local\"]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    env_mode: EnvModeType\n",
    "    selected_subsets: List[str] = field(\n",
    "        default_factory=lambda: [\"SUDOKU_4\", \"SUDOKU_5\", \"SUDOKU_6\"]\n",
    "    )\n",
    "\n",
    "    # Derived fields (init=False)\n",
    "    data_root: Path = field(init=False)\n",
    "    base_dir: Path = field(init=False)\n",
    "    taco_raw_dir: Path = field(init=False)\n",
    "    taco_file_paths: List[Path] = field(init=False)\n",
    "    normalized_sets_dir: Path = field(init=False)\n",
    "    finetune_dir: Path = field(init=False)\n",
    "    train_dir: Path = field(init=False)\n",
    "    val_dir: Path = field(init=False)\n",
    "    test_dir: Path = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        # Set data_root based on env_mode (defaults; override in factory if needed)\n",
    "        data_root_map = {\n",
    "            # \"local\": Path.home() / \"mnt/shared\",\n",
    "            \"local\": Path(\"/mnt/shared\"),\n",
    "            # \"remote\": Path(\"/mnt/data\"),\n",
    "            \"remote\": Path.home(),\n",
    "            \"colab\": Path(\"/content/drive/MyDrive\"),\n",
    "        }\n",
    "        object.__setattr__(\n",
    "            self, \"data_root\", data_root_map.get(self.env_mode, Path.cwd())\n",
    "        )\n",
    "\n",
    "        # Derive other paths\n",
    "        object.__setattr__(self, \"base_dir\", self.data_root / \"datasets/sen2venus\")\n",
    "        # object.__setattr__(self, \"taco_raw_dir\", self.base_dir / \"TACO_raw_data\")\n",
    "        # object.__setattr__(\n",
    "        #     self,\n",
    "        #     \"taco_file_paths\",\n",
    "        #     [self.taco_raw_dir / f\"{subset}.taco\" for subset in self.selected_subsets],\n",
    "        # )\n",
    "        object.__setattr__(\n",
    "            self, \"normalized_sets_dir\", self.base_dir / \"normalized_sets\"\n",
    "        )\n",
    "        object.__setattr__(self, \"finetune_dir\", self.base_dir / \"finetune\")\n",
    "        object.__setattr__(self, \"train_dir\", self.normalized_sets_dir / \"train\")\n",
    "        object.__setattr__(self, \"val_dir\", self.normalized_sets_dir / \"val\")\n",
    "        object.__setattr__(self, \"test_dir\", self.normalized_sets_dir / \"test\")\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        \"\"\"Validate config paths exist; raise errors otherwise.\"\"\"\n",
    "        missing_paths = []\n",
    "        for attr in [\n",
    "            \"data_root\",\n",
    "            \"base_dir\",\n",
    "            # \"taco_raw_dir\",\n",
    "            \"normalized_sets_dir\",\n",
    "            \"finetune_dir\",\n",
    "            \"train_dir\",\n",
    "            \"val_dir\",\n",
    "            \"test_dir\",\n",
    "        ]:\n",
    "            path: Path = getattr(self, attr)\n",
    "            if not path.exists():\n",
    "                missing_paths.append(str(path))\n",
    "        if missing_paths:\n",
    "            raise ValueError(f\"Missing paths: {', '.join(missing_paths)}\")\n",
    "        # for file_path in self.taco_file_paths:\n",
    "        #     if not file_path.exists():\n",
    "        #         missing_paths.append(str(file_path))\n",
    "        if missing_paths:\n",
    "            raise ValueError(f\"Missing taco files: {', '.join(missing_paths)}\")\n",
    "\n",
    "\n",
    "def setup_environment(env_mode: EnvModeType) -> None:\n",
    "    \"\"\"Perform environment-specific setup (side effects isolated here).\"\"\"\n",
    "    if env_mode == \"colab\":\n",
    "        try:\n",
    "            import super_image\n",
    "        except ImportError:\n",
    "            print(\"Installing 'super-image'...\")\n",
    "            try:\n",
    "                subprocess.run([\"pip\", \"install\", \"--quiet\", \"super-image\"], check=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                raise RuntimeError(f\"Failed to install super-image: {e}\")\n",
    "\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "\n",
    "            drive.mount(\"/content/drive\", force_remount=True)\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\"Google Colab module not found. Are you in Colab?\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to mount Google Drive: {e}\")\n",
    "\n",
    "        # Optional: Copy data to local /content for faster I/O in Colab\n",
    "        colab_vm_dir = Path(\"/content/taco_normalized\")\n",
    "        if not colab_vm_dir.exists():\n",
    "            print(\"Copying normalized data to local Colab storage for performance...\")\n",
    "            shutil.copytree(\n",
    "                Path(\"/content/drive/MyDrive/datasets/sen2venus/normalized_sets\"),\n",
    "                colab_vm_dir,\n",
    "            )\n",
    "            print(\"Copy complete.\")\n",
    "        # Avoid os.chdir; let users handle working dir if needed\n",
    "\n",
    "    elif env_mode == \"remote\":\n",
    "        print(\"Remote environment detected. No specific setup needed.\")\n",
    "\n",
    "    elif env_mode == \"local\":\n",
    "        print(\"Local environment detected. Ensuring dependencies...\")\n",
    "\n",
    "\n",
    "def create_config(env_mode: EnvModeType | None = None) -> Config:\n",
    "    \"\"\"Factory to create and setup config based on detected environment.\"\"\"\n",
    "    if env_mode is None:\n",
    "        if \"google.colab\" in sys.modules:\n",
    "            env_mode = \"colab\"\n",
    "        elif \"REMOTE_ENV_VAR\" in os.environ:\n",
    "            env_mode = \"remote\"\n",
    "        else:\n",
    "            env_mode = \"local\"\n",
    "\n",
    "    setup_environment(env_mode)\n",
    "    config = Config(env_mode=env_mode)\n",
    "    config.validate()\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65be02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_config(\"colab\")\n",
    "print(config.data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e88631",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "from super_image import PreTrainedModel, TrainingArguments\n",
    "from super_image.models import EdsrModel\n",
    "from super_image.trainer import Trainer, logger\n",
    "from super_image.utils.metrics import AverageMeter\n",
    "from super_image.file_utils import WEIGHTS_NAME, WEIGHTS_NAME_SCALE\n",
    "\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6795760",
   "metadata": {},
   "source": [
    "## logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"Function to set up a dedicated logger.\"\"\"\n",
    "    log_path = Path(log_file)\n",
    "    # Create parent directory if it doesn't exist\n",
    "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # To prevent logs from being duplicated in multiple runs of the same cell\n",
    "    if name in logging.Logger.manager.loggerDict:\n",
    "        logger = logging.getLogger(name)\n",
    "        logger.handlers.clear()  # Clear existing handlers\n",
    "    else:\n",
    "        logger = logging.getLogger(name)\n",
    "\n",
    "    # File handler to save logs to a file\n",
    "    file_handler = logging.FileHandler(log_file, mode=\"w\")  # 'w' to overwrite old log\n",
    "    file_handler.setFormatter(\n",
    "        logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    )\n",
    "\n",
    "    # Stream handler to show logs in the notebook output\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Define the log file path within the experiment's output directory\n",
    "output_dir_8_block = config.finetune_dir / \"edsr_base_8_block\"\n",
    "log_file_8_block = output_dir_8_block / \"training_log_8_block.log\"\n",
    "logger_8_block = setup_logger(\"8_block_experiment\", log_file_8_block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a573f",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNormalizedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Efficiently reads pre-processed, sharded tensor files from disk.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shard_dir: Union[str, Path]):\n",
    "        self.shard_dir = Path(shard_dir)\n",
    "        self.shard_paths: List[Path] = sorted(self.shard_dir.glob(\"*.pt\"))\n",
    "\n",
    "        if not self.shard_paths:\n",
    "            raise ValueError(f\"No shard files ('*.pt') found in {self.shard_dir}\")\n",
    "\n",
    "        # To calculate length, we check the size of the first shard and assume\n",
    "        # all but the last are the same size.\n",
    "        first_shard = torch.load(self.shard_paths[0])\n",
    "        self.shard_size = len(first_shard)\n",
    "        last_shard = torch.load(self.shard_paths[-1])\n",
    "        self.length = (len(self.shard_paths) - 1) * self.shard_size + len(last_shard)\n",
    "\n",
    "        # Simple cache to avoid re-loading the same shard consecutively\n",
    "        self._cache = {}\n",
    "        self._cached_shard_index = -1\n",
    "        print(\n",
    "            f\"Initialized dataset from {self.shard_dir} with {self.length} samples across {len(self.shard_paths)} shards.\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, np.ndarray]:\n",
    "        shard_index = idx // self.shard_size\n",
    "        index_in_shard = idx % self.shard_size\n",
    "\n",
    "        if shard_index != self._cached_shard_index:\n",
    "            self._cache = torch.load(self.shard_paths[shard_index])\n",
    "            self._cached_shard_index = shard_index\n",
    "\n",
    "        # coupled with TACORGBDataset dataset class\n",
    "        # each item in the shard is a squeezed dictionary with keys lr and hr\n",
    "        squeezed_sample = self._cache[index_in_shard]\n",
    "        return squeezed_sample[\"lr\"], squeezed_sample[\"hr\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfe328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreNormalizedDataset(config.train_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = PreNormalizedDataset(config.val_dir)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "test_dataset = PreNormalizedDataset(config.test_dir)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ef0f0",
   "metadata": {},
   "source": [
    "# Load EDSR-baseline and configure 8-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f118341",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomTrainingArguments(TrainingArguments):\n",
    "    warmup_steps: int = 0\n",
    "    save_steps: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7eeafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_8_block.info(\"--- CONFIGURING 8-BLOCK ARCHITECTURE EXPERIMENT ---\")\n",
    "\n",
    "args_8_block = CustomTrainingArguments(\n",
    "    output_dir=output_dir_8_block,\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,\n",
    "    warmup_steps=500,\n",
    ")\n",
    "\n",
    "logger_8_block.info(f\"Training arguments: {args_8_block}\")\n",
    "\n",
    "logger_8_block.info(\"Instantiating 8-block EDSR model (training from scratch).\")\n",
    "# This creates a new model with half the number of residual blocks.\n",
    "# The weights will be randomly initialized, NOT pre-trained.\n",
    "model_8_block = EdsrModel.from_pretrained(\n",
    "    \"eugenesiow/edsr-base\", scale=2, n_resblocks=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484277d",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResumableTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "    def save_checkpoint(self, epoch, global_step, is_best=False):\n",
    "        output_dir = self.args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = (\n",
    "            \"best_model_checkpoint.pt\" if is_best else \"latest_step_checkpoint.pt\"\n",
    "        )\n",
    "        checkpoint_path = os.path.join(output_dir, filename)\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "            \"best_metric\": self.best_metric,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(state, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path} (step {global_step})\")\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        output_dir = self.args.output_dir\n",
    "        checkpoint_path = os.path.join(output_dir, \"latest_step_checkpoint.pt\")\n",
    "        start_epoch, global_step = 0, 0\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            logger.warning(\"No checkpoint found. Starting from scratch.\")\n",
    "            return start_epoch, global_step\n",
    "        try:\n",
    "            state = torch.load(checkpoint_path, map_location=self.args.device)\n",
    "            self.model.load_state_dict(state[\"model_state_dict\"])\n",
    "            if self.optimizer is None:\n",
    "                self._create_optimizer_and_scheduler()\n",
    "            self.optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
    "            self.scheduler.load_state_dict(state[\"scheduler_state_dict\"])\n",
    "            self.best_metric = state.get(\"best_metric\", 0.0)\n",
    "            start_epoch = state[\"epoch\"]\n",
    "            global_step = state[\"global_step\"]\n",
    "            logger.info(\n",
    "                f\"Successfully loaded checkpoint. Resuming from epoch {start_epoch}, step {global_step}.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load checkpoint: {e}. Starting from scratch.\")\n",
    "            start_epoch, global_step = 0, 0\n",
    "        return start_epoch, global_step\n",
    "\n",
    "    def save_model(self, output_dir: str = None):\n",
    "        \"\"\"\n",
    "        Overrides the faulty base save_model method to correctly handle\n",
    "        models wrapped in nn.DataParallel.\n",
    "        \"\"\"\n",
    "        output_dir = output_dir if output_dir is not None else self.args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Determine if the model is the raw model or a wrapped one\n",
    "        model_to_save = (\n",
    "            self.model.module\n",
    "            if isinstance(self.model, torch.nn.DataParallel)\n",
    "            else self.model\n",
    "        )\n",
    "\n",
    "        # call save_pretrained on the actual model\n",
    "        if isinstance(model_to_save, PreTrainedModel):\n",
    "            model_to_save.save_pretrained(output_dir)\n",
    "        else:\n",
    "            # Fallback for non-PreTrainedModel, though EDSR is one.\n",
    "            # This part is for full compatibility with the original's logic.\n",
    "            logger.warning(\"Saving a model that is not a PreTrainedModel.\")\n",
    "            scale = model_to_save.config.scale\n",
    "            if scale is not None:\n",
    "                weights_name = WEIGHTS_NAME_SCALE.format(scale=scale)\n",
    "            else:\n",
    "                weights_name = WEIGHTS_NAME\n",
    "            weights = copy.deepcopy(model_to_save.state_dict())\n",
    "            torch.save(weights, os.path.join(output_dir, weights_name))\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        self.scheduler = lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=999999, gamma=1.0\n",
    "        )  # Dummy scheduler, we control LR manually\n",
    "\n",
    "    def train(self, **kwargs):\n",
    "        \"\"\"The definitive, fully resumable training loop with the tuple unpacking fix.\"\"\"\n",
    "        self._create_optimizer_and_scheduler()\n",
    "\n",
    "        # Unpack the tuple into two separate integer variables.\n",
    "        start_epoch, global_step = self.load_checkpoint()\n",
    "\n",
    "        train_dataloader = self.get_train_dataloader()\n",
    "\n",
    "        for epoch in range(start_epoch, self.args.num_train_epochs):\n",
    "            self.model.train()\n",
    "            epoch_losses = AverageMeter()\n",
    "\n",
    "            # Using an enumerated dataloader to skip steps correctly\n",
    "            with tqdm(\n",
    "                total=len(train_dataloader),\n",
    "                desc=f\"Epoch {epoch}/{self.args.num_train_epochs - 1}\",\n",
    "            ) as t:\n",
    "                for step, data in enumerate(train_dataloader):\n",
    "                    # This logic allows us to resume mid-epoch\n",
    "                    current_epoch_step = epoch * len(train_dataloader) + step\n",
    "                    if current_epoch_step < global_step:\n",
    "                        t.update(1)\n",
    "                        continue\n",
    "\n",
    "                    # Learning Rate Scheduling (Warm-up + Decay)\n",
    "                    if global_step < self.args.warmup_steps:\n",
    "                        lr_scale = (\n",
    "                            float(global_step) / float(self.args.warmup_steps)\n",
    "                            if self.args.warmup_steps > 0\n",
    "                            else 1.0\n",
    "                        )\n",
    "                        new_lr = self.args.learning_rate * lr_scale\n",
    "                    else:\n",
    "                        divisor = max(1, int(self.args.num_train_epochs * 0.8))\n",
    "                        new_lr = self.args.learning_rate * (0.1 ** (epoch // divisor))\n",
    "\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        param_group[\"lr\"] = new_lr\n",
    "\n",
    "                    # Standard training steps\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = (\n",
    "                        inputs.to(self.args.device),\n",
    "                        labels.to(self.args.device),\n",
    "                    )\n",
    "                    preds = self.model(inputs)\n",
    "                    loss = torch.nn.L1Loss()(preds, labels)\n",
    "                    epoch_losses.update(loss.item(), len(inputs))\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    global_step += 1\n",
    "                    t.set_postfix(loss=f\"{epoch_losses.avg:.6f}\", lr=f\"{new_lr:.2e}\")\n",
    "                    t.update(1)\n",
    "\n",
    "                    # Step-Based Checkpointing\n",
    "                    if global_step > 0 and global_step % self.args.save_steps == 0:\n",
    "                        self.save_checkpoint(epoch, global_step, is_best=False)\n",
    "\n",
    "            # Epoch-Based Evaluation and Best Model Saving\n",
    "            self.eval(epoch)\n",
    "            if self.best_epoch == epoch:\n",
    "                self.save_checkpoint(epoch, global_step, is_best=True)\n",
    "\n",
    "\n",
    "class CustomResumableTrainerLogger(CustomResumableTrainer): \n",
    "    def __init__(self, *args, logger=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Use the provided logger, or fall back to the default `super_image.trainer` logger\n",
    "        self.log = logger if logger is not None else super_image_logger\n",
    "\n",
    "    def save_checkpoint(self, epoch, global_step, is_best=False):\n",
    "        super().save_checkpoint(epoch, global_step, is_best)\n",
    "        self.log.info(f\"Saved checkpoint for epoch {epoch} at step {global_step}.\")\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.log.info(\"Attempting to load checkpoint...\")\n",
    "        start_epoch, global_step = super().load_checkpoint()\n",
    "        self.log.info(f\"Load result: Resuming from epoch {start_epoch}, step {global_step}.\")\n",
    "        return start_epoch, global_step\n",
    "\n",
    "    def eval(self, epoch):\n",
    "        super().eval(epoch)\n",
    "        self.log.info(f\"EVALUATION Epoch {epoch}: PSNR={self.best_metric:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_8_block.info(\"Instantiating Resumable Trainer with logs.\")\n",
    "trainer_8_block = CustomResumableTrainerLogger(\n",
    "    model=model_8_block,\n",
    "    args=args_8_block,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    logger=logger_8_block,  \n",
    ")\n",
    "\n",
    "\n",
    "logger_8_block.info(\"--- LAUNCHING TRAINING ---\")\n",
    "try:\n",
    "    trainer_8_block.train()\n",
    "    logger_8_block.info(\"--- TRAINING COMPLETE ---\")\n",
    "\n",
    "    final_best_epoch = trainer_8_block.best_epoch\n",
    "    final_best_psnr = trainer_8_block.best_metric\n",
    "    logger_8_block.info(\n",
    "        f\"Best model for 8-block architecture found at epoch {final_best_epoch} with PSNR: {final_best_psnr:.4f}\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    logger_8_block.error(f\"--- TRAINING FAILED ---: {e}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
