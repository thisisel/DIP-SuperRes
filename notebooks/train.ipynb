{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6e56bc",
   "metadata": {},
   "source": [
    "# Env Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaf1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28fec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 15 17:54:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     Off |   00000000:00:07.0 Off |                  N/A |\n",
      "| 30%   44C    P0             N/A /  350W |       1MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d47f7",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10764955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Union, Dict\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "EnvModeType = Literal[\"colab\", \"remote\", \"local\"]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    env_mode: EnvModeType\n",
    "    selected_subsets: List[str] = field(\n",
    "        default_factory=lambda: [\"SUDOKU_4\", \"SUDOKU_5\", \"SUDOKU_6\"]\n",
    "    )\n",
    "\n",
    "    # Derived fields (init=False)\n",
    "    data_root: Path = field(init=False)\n",
    "    base_dir: Path = field(init=False)\n",
    "    taco_raw_dir: Path = field(init=False)\n",
    "    taco_file_paths: List[Path] = field(init=False)\n",
    "    normalized_sets_dir: Path = field(init=False)\n",
    "    finetune_dir: Path = field(init=False)\n",
    "    train_dir: Path = field(init=False)\n",
    "    val_dir: Path = field(init=False)\n",
    "    test_dir: Path = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        # Set data_root based on env_mode (defaults; override in factory if needed)\n",
    "        data_root_map = {\n",
    "            # \"local\": Path.home() / \"mnt/shared\",\n",
    "            \"local\": Path(\"/mnt/shared\"),\n",
    "            # \"remote\": Path(\"/mnt/data\"),\n",
    "            \"remote\": Path.home(),\n",
    "            \"colab\": Path(\"/content/drive/MyDrive\"),\n",
    "        }\n",
    "        object.__setattr__(\n",
    "            self, \"data_root\", data_root_map.get(self.env_mode, Path.cwd())\n",
    "        )\n",
    "\n",
    "        # Derive other paths\n",
    "        object.__setattr__(self, \"base_dir\", self.data_root / \"datasets/sen2venus\")\n",
    "        # object.__setattr__(self, \"taco_raw_dir\", self.base_dir / \"TACO_raw_data\")\n",
    "        # object.__setattr__(\n",
    "        #     self,\n",
    "        #     \"taco_file_paths\",\n",
    "        #     [self.taco_raw_dir / f\"{subset}.taco\" for subset in self.selected_subsets],\n",
    "        # )\n",
    "        object.__setattr__(\n",
    "            self, \"normalized_sets_dir\", self.base_dir / \"normalized_sets\"\n",
    "        )\n",
    "        object.__setattr__(self, \"finetune_dir\", self.base_dir / \"finetune\")\n",
    "        object.__setattr__(self, \"train_dir\", self.normalized_sets_dir / \"train\")\n",
    "        object.__setattr__(self, \"val_dir\", self.normalized_sets_dir / \"val\")\n",
    "        object.__setattr__(self, \"test_dir\", self.normalized_sets_dir / \"test\")\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        \"\"\"Validate config paths exist; raise errors otherwise.\"\"\"\n",
    "        missing_paths = []\n",
    "        for attr in [\n",
    "            \"data_root\",\n",
    "            \"base_dir\",\n",
    "            # \"taco_raw_dir\",\n",
    "            \"normalized_sets_dir\",\n",
    "            \"finetune_dir\",\n",
    "            \"train_dir\",\n",
    "            \"val_dir\",\n",
    "            \"test_dir\",\n",
    "        ]:\n",
    "            path: Path = getattr(self, attr)\n",
    "            if not path.exists():\n",
    "                missing_paths.append(str(path))\n",
    "        if missing_paths:\n",
    "            raise ValueError(f\"Missing paths: {', '.join(missing_paths)}\")\n",
    "        # for file_path in self.taco_file_paths:\n",
    "        #     if not file_path.exists():\n",
    "        #         missing_paths.append(str(file_path))\n",
    "        if missing_paths:\n",
    "            raise ValueError(f\"Missing taco files: {', '.join(missing_paths)}\")\n",
    "\n",
    "\n",
    "def setup_environment(env_mode: EnvModeType) -> None:\n",
    "    \"\"\"Perform environment-specific setup (side effects isolated here).\"\"\"\n",
    "    if env_mode == \"colab\":\n",
    "        try:\n",
    "            import super_image\n",
    "        except ImportError:\n",
    "            print(\"Installing 'super-image'...\")\n",
    "            try:\n",
    "                subprocess.run([\"pip\", \"install\", \"--quiet\", \"super-image\"], check=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                raise RuntimeError(f\"Failed to install super-image: {e}\")\n",
    "\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "\n",
    "            drive.mount(\"/content/drive\", force_remount=True)\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\"Google Colab module not found. Are you in Colab?\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to mount Google Drive: {e}\")\n",
    "\n",
    "        # Optional: Copy data to local /content for faster I/O in Colab\n",
    "        colab_vm_dir = Path(\"/content/taco_normalized\")\n",
    "        if not colab_vm_dir.exists():\n",
    "            print(\"Copying normalized data to local Colab storage for performance...\")\n",
    "            shutil.copytree(\n",
    "                Path(\"/content/drive/MyDrive/datasets/sen2venus/normalized_sets\"),\n",
    "                colab_vm_dir,\n",
    "            )\n",
    "            print(\"Copy complete.\")\n",
    "        # Avoid os.chdir; let users handle working dir if needed\n",
    "\n",
    "    elif env_mode == \"remote\":\n",
    "        print(\"Remote environment detected. No specific setup needed.\")\n",
    "\n",
    "    elif env_mode == \"local\":\n",
    "        print(\"Local environment detected. Ensuring dependencies...\")\n",
    "\n",
    "\n",
    "def create_config(env_mode: EnvModeType | None = None) -> Config:\n",
    "    \"\"\"Factory to create and setup config based on detected environment.\"\"\"\n",
    "    if env_mode is None:\n",
    "        if \"google.colab\" in sys.modules:\n",
    "            env_mode = \"colab\"\n",
    "        elif \"REMOTE_ENV_VAR\" in os.environ:\n",
    "            env_mode = \"remote\"\n",
    "        else:\n",
    "            env_mode = \"local\"\n",
    "\n",
    "    setup_environment(env_mode)\n",
    "    config = Config(env_mode=env_mode)\n",
    "    config.validate()\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65be02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote environment detected. No specific setup needed.\n",
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "config = create_config(\"remote\")\n",
    "print(config.data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e88631",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b99b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "from super_image import PreTrainedModel, TrainingArguments,EdsrConfig\n",
    "from super_image.models import EdsrModel\n",
    "from super_image.trainer import Trainer, logger\n",
    "from super_image.utils.metrics import AverageMeter\n",
    "from super_image.file_utils import WEIGHTS_NAME, WEIGHTS_NAME_SCALE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6795760",
   "metadata": {},
   "source": [
    "## logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edcf3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"Function to set up a dedicated logger.\"\"\"\n",
    "    log_path = Path(log_file)\n",
    "    # Create parent directory if it doesn't exist\n",
    "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # To prevent logs from being duplicated in multiple runs of the same cell\n",
    "    if name in logging.Logger.manager.loggerDict:\n",
    "        logger = logging.getLogger(name)\n",
    "        logger.handlers.clear()  # Clear existing handlers\n",
    "    else:\n",
    "        logger = logging.getLogger(name)\n",
    "\n",
    "    # File handler to save logs to a file\n",
    "    file_handler = logging.FileHandler(log_file, mode=\"w\")  # 'w' to overwrite old log\n",
    "    file_handler.setFormatter(\n",
    "        logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    )\n",
    "\n",
    "    # Stream handler to show logs in the notebook output\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Define the log file path within the experiment's output directory\n",
    "output_dir_8_block = config.finetune_dir / \"edsr_base_8_block\"\n",
    "log_file_8_block = output_dir_8_block / \"training_log_8_block.log\"\n",
    "logger_8_block = setup_logger(\"8_block_experiment\", log_file_8_block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a573f",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNormalizedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Efficiently reads pre-processed, sharded tensor files from disk.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shard_dir: Union[str, Path]):\n",
    "        self.shard_dir = Path(shard_dir)\n",
    "        self.shard_paths: List[Path] = sorted(self.shard_dir.glob(\"*.pt\"))\n",
    "\n",
    "        if not self.shard_paths:\n",
    "            raise ValueError(f\"No shard files ('*.pt') found in {self.shard_dir}\")\n",
    "\n",
    "        # To calculate length, we check the size of the first shard and assume\n",
    "        # all but the last are the same size.\n",
    "        first_shard = torch.load(self.shard_paths[0])\n",
    "        self.shard_size = len(first_shard)\n",
    "        last_shard = torch.load(self.shard_paths[-1])\n",
    "        self.length = (len(self.shard_paths) - 1) * self.shard_size + len(last_shard)\n",
    "\n",
    "        # Simple cache to avoid re-loading the same shard consecutively\n",
    "        self._cache = {}\n",
    "        self._cached_shard_index = -1\n",
    "        print(\n",
    "            f\"Initialized dataset from {self.shard_dir} with {self.length} samples across {len(self.shard_paths)} shards.\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, np.ndarray]:\n",
    "        shard_index = idx // self.shard_size\n",
    "        index_in_shard = idx % self.shard_size\n",
    "\n",
    "        if shard_index != self._cached_shard_index:\n",
    "            self._cache = torch.load(self.shard_paths[shard_index])\n",
    "            self._cached_shard_index = shard_index\n",
    "\n",
    "        # coupled with TACORGBDataset dataset class\n",
    "        # each item in the shard is a squeezed dictionary with keys lr and hr\n",
    "        squeezed_sample = self._cache[index_in_shard]\n",
    "        return squeezed_sample[\"lr\"], squeezed_sample[\"hr\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbfe328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset from /home/ubuntu/datasets/sen2venus/normalized_sets/train with 4436 samples across 5 shards.\n",
      "Initialized dataset from /home/ubuntu/datasets/sen2venus/normalized_sets/val with 554 samples across 1 shards.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PreNormalizedDataset(config.train_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = PreNormalizedDataset(config.val_dir)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# test_dataset = PreNormalizedDataset(config.test_dir)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ef0f0",
   "metadata": {},
   "source": [
    "# Load EDSR-baseline and configure 8-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f118341",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomTrainingArguments(TrainingArguments):\n",
    "    warmup_steps: int = 0\n",
    "    save_steps: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7eeafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- CONFIGURING 8-BLOCK ARCHITECTURE EXPERIMENT ---\n",
      "Instantiating 8-block EDSR model (training from scratch).\n"
     ]
    }
   ],
   "source": [
    "logger_8_block.info(\"--- CONFIGURING 8-BLOCK ARCHITECTURE EXPERIMENT ---\")\n",
    "\n",
    "config_edsr_8block = EdsrConfig(\n",
    "    scale=2,  \n",
    "    n_resblocks=8,\n",
    ")\n",
    "\n",
    "\n",
    "logger_8_block.info(\"Instantiating 8-block EDSR model (training from scratch).\")\n",
    "# This creates a new model with half the number of residual blocks.\n",
    "# The weights will be randomly initialized, NOT pre-trained.\n",
    "model_8_block = EdsrModel(config_edsr_8block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484277d",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b8a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResumableTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "    def save_checkpoint(self, epoch, global_step, is_best=False):\n",
    "        output_dir = self.args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = (\n",
    "            \"best_model_checkpoint.pt\" if is_best else \"latest_step_checkpoint.pt\"\n",
    "        )\n",
    "        checkpoint_path = os.path.join(output_dir, filename)\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "            \"best_metric\": self.best_metric,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(state, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path} (step {global_step})\")\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        output_dir = self.args.output_dir\n",
    "        checkpoint_path = os.path.join(output_dir, \"latest_step_checkpoint.pt\")\n",
    "        start_epoch, global_step = 0, 0\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            logger.warning(\"No checkpoint found. Starting from scratch.\")\n",
    "            return start_epoch, global_step\n",
    "        try:\n",
    "            state = torch.load(checkpoint_path, map_location=self.args.device)\n",
    "            self.model.load_state_dict(state[\"model_state_dict\"])\n",
    "            if self.optimizer is None:\n",
    "                self._create_optimizer_and_scheduler()\n",
    "            self.optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
    "            self.scheduler.load_state_dict(state[\"scheduler_state_dict\"])\n",
    "            self.best_metric = state.get(\"best_metric\", 0.0)\n",
    "            start_epoch = state[\"epoch\"]\n",
    "            global_step = state[\"global_step\"]\n",
    "            logger.info(\n",
    "                f\"Successfully loaded checkpoint. Resuming from epoch {start_epoch}, step {global_step}.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load checkpoint: {e}. Starting from scratch.\")\n",
    "            start_epoch, global_step = 0, 0\n",
    "        return start_epoch, global_step\n",
    "\n",
    "    def save_model(self, output_dir: str = None):\n",
    "        \"\"\"\n",
    "        Overrides the faulty base save_model method to correctly handle\n",
    "        models wrapped in nn.DataParallel.\n",
    "        \"\"\"\n",
    "        output_dir = output_dir if output_dir is not None else self.args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Determine if the model is the raw model or a wrapped one\n",
    "        model_to_save = (\n",
    "            self.model.module\n",
    "            if isinstance(self.model, torch.nn.DataParallel)\n",
    "            else self.model\n",
    "        )\n",
    "\n",
    "        # call save_pretrained on the actual model\n",
    "        if isinstance(model_to_save, PreTrainedModel):\n",
    "            model_to_save.save_pretrained(output_dir)\n",
    "        else:\n",
    "            # Fallback for non-PreTrainedModel, though EDSR is one.\n",
    "            # This part is for full compatibility with the original's logic.\n",
    "            logger.warning(\"Saving a model that is not a PreTrainedModel.\")\n",
    "            scale = model_to_save.config.scale\n",
    "            if scale is not None:\n",
    "                weights_name = WEIGHTS_NAME_SCALE.format(scale=scale)\n",
    "            else:\n",
    "                weights_name = WEIGHTS_NAME\n",
    "            weights = copy.deepcopy(model_to_save.state_dict())\n",
    "            torch.save(weights, os.path.join(output_dir, weights_name))\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        self.scheduler = lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=999999, gamma=1.0\n",
    "        )  # Dummy scheduler, we control LR manually\n",
    "\n",
    "    def train(self, **kwargs):\n",
    "        \"\"\"The definitive, fully resumable training loop with the tuple unpacking fix.\"\"\"\n",
    "        self._create_optimizer_and_scheduler()\n",
    "\n",
    "        # Unpack the tuple into two separate integer variables.\n",
    "        start_epoch, global_step = self.load_checkpoint()\n",
    "\n",
    "        train_dataloader = self.get_train_dataloader()\n",
    "\n",
    "        for epoch in range(start_epoch, self.args.num_train_epochs):\n",
    "            self.model.train()\n",
    "            epoch_losses = AverageMeter()\n",
    "\n",
    "            # Using an enumerated dataloader to skip steps correctly\n",
    "            with tqdm(\n",
    "                total=len(train_dataloader),\n",
    "                desc=f\"Epoch {epoch}/{self.args.num_train_epochs - 1}\",\n",
    "            ) as t:\n",
    "                for step, data in enumerate(train_dataloader):\n",
    "                    # This logic allows us to resume mid-epoch\n",
    "                    current_epoch_step = epoch * len(train_dataloader) + step\n",
    "                    if current_epoch_step < global_step:\n",
    "                        t.update(1)\n",
    "                        continue\n",
    "\n",
    "                    # Learning Rate Scheduling (Warm-up + Decay)\n",
    "                    if global_step < self.args.warmup_steps:\n",
    "                        lr_scale = (\n",
    "                            float(global_step) / float(self.args.warmup_steps)\n",
    "                            if self.args.warmup_steps > 0\n",
    "                            else 1.0\n",
    "                        )\n",
    "                        new_lr = self.args.learning_rate * lr_scale\n",
    "                    else:\n",
    "                        divisor = max(1, int(self.args.num_train_epochs * 0.8))\n",
    "                        new_lr = self.args.learning_rate * (0.1 ** (epoch // divisor))\n",
    "\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        param_group[\"lr\"] = new_lr\n",
    "\n",
    "                    # Standard training steps\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = (\n",
    "                        inputs.to(self.args.device),\n",
    "                        labels.to(self.args.device),\n",
    "                    )\n",
    "                    preds = self.model(inputs)\n",
    "                    loss = torch.nn.L1Loss()(preds, labels)\n",
    "                    epoch_losses.update(loss.item(), len(inputs))\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    global_step += 1\n",
    "                    t.set_postfix(loss=f\"{epoch_losses.avg:.6f}\", lr=f\"{new_lr:.2e}\")\n",
    "                    t.update(1)\n",
    "\n",
    "                    # Step-Based Checkpointing\n",
    "                    if global_step > 0 and global_step % self.args.save_steps == 0:\n",
    "                        self.save_checkpoint(epoch, global_step, is_best=False)\n",
    "\n",
    "            # Epoch-Based Evaluation and Best Model Saving\n",
    "            self.eval(epoch)\n",
    "            if self.best_epoch == epoch:\n",
    "                self.save_checkpoint(epoch, global_step, is_best=True)\n",
    "\n",
    "\n",
    "class CustomResumableTrainerLogger(CustomResumableTrainer): \n",
    "    def __init__(self, *args, logger=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Use the provided logger, or fall back to the default `super_image.trainer` logger\n",
    "        self.log = logger if logger is not None else super_image_logger\n",
    "\n",
    "    def save_checkpoint(self, epoch, global_step, is_best=False):\n",
    "        super().save_checkpoint(epoch, global_step, is_best)\n",
    "        self.log.info(f\"Saved checkpoint for epoch {epoch} at step {global_step}.\")\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.log.info(\"Attempting to load checkpoint...\")\n",
    "        start_epoch, global_step = super().load_checkpoint()\n",
    "        self.log.info(f\"Load result: Resuming from epoch {start_epoch}, step {global_step}.\")\n",
    "        return start_epoch, global_step\n",
    "\n",
    "    def eval(self, epoch):\n",
    "        super().eval(epoch)\n",
    "        self.log.info(f\"EVALUATION Epoch {epoch}: PSNR={self.best_metric:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e062ff3d-9d1a-44a9-b9c5-9c019ea409eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training arguments: CustomTrainingArguments(output_dir=PosixPath('/home/ubuntu/datasets/sen2venus/finetune/edsr_base_8_block'), overwrite_output_dir=False, learning_rate=0.0001, gamma=0.5, num_train_epochs=15, save_steps=500, save_total_limit=None, no_cuda=False, seed=123, fp16=False, per_device_train_batch_size=16, local_rank=-1, dataloader_num_workers=0, dataloader_pin_memory=True, warmup_steps=500)\n"
     ]
    }
   ],
   "source": [
    "args_8_block = CustomTrainingArguments(\n",
    "    output_dir=output_dir_8_block,\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,\n",
    "    warmup_steps=500,\n",
    ")\n",
    "\n",
    "logger_8_block.info(f\"Training arguments: {args_8_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0669215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instantiating Resumable Trainer with logs.\n",
      "--- LAUNCHING TRAINING ---\n",
      "Attempting to load checkpoint...\n",
      "No checkpoint found. Starting from scratch.\n",
      "Load result: Resuming from epoch 0, step 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ee134c46b94e7fb540d0c88acf52f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 0: PSNR=45.4047\n",
      "Saved checkpoint for epoch 0 at step 278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 45.40     ssim: 0.9855\n",
      "best epoch: 0, psnr: 45.404720, ssim: 0.985482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab9040976fb48b28e2aabd9b1faacc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 1 at step 500.\n",
      "EVALUATION Epoch 1: PSNR=45.4047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 44.54     ssim: 0.9872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db570bae07f64d97bb2f7c23b49d5f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 3 at step 1000.\n",
      "EVALUATION Epoch 3: PSNR=46.1685\n",
      "Saved checkpoint for epoch 3 at step 1112.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.17     ssim: 0.9884\n",
      "best epoch: 3, psnr: 46.168545, ssim: 0.988413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979aba17afe441919d7a315608da3d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 4: PSNR=46.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 45.91     ssim: 0.9885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444247948a7b4e9a82dc3939064464df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 5 at step 1500.\n",
      "EVALUATION Epoch 5: PSNR=46.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.11     ssim: 0.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d330138e57b46f789539954084900f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 6: PSNR=46.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.05     ssim: 0.9887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c9cebdd87b4e33a9cd028c99049c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 7 at step 2000.\n",
      "EVALUATION Epoch 7: PSNR=46.3109\n",
      "Saved checkpoint for epoch 7 at step 2224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.31     ssim: 0.9887\n",
      "best epoch: 7, psnr: 46.310905, ssim: 0.988743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf746d014af4af38eac012d46d1c50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 8 at step 2500.\n",
      "EVALUATION Epoch 8: PSNR=46.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 45.59     ssim: 0.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fad5f90d264cd69432c94c3b38f578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 9: PSNR=46.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.29     ssim: 0.9889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23315282885c4b42998ca648ef7fb243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 10 at step 3000.\n",
      "EVALUATION Epoch 10: PSNR=46.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.18     ssim: 0.9888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8d97c269784f9dbdbbc16533bcbb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 11: PSNR=46.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.17     ssim: 0.9889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934d3affd0954f88ac0f814904f3db15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 12 at step 3500.\n",
      "EVALUATION Epoch 12: PSNR=46.4834\n",
      "Saved checkpoint for epoch 12 at step 3614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.48     ssim: 0.9891\n",
      "best epoch: 12, psnr: 46.483364, ssim: 0.989063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b649685b3f264a9da09ff918e7973bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATION Epoch 13: PSNR=46.4834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.47     ssim: 0.9891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559566be85ef41009b879989c67b8a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/14:   0%|          | 0/278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "EVALUATION Epoch 14: PSNR=46.5171\n",
      "Saved checkpoint for epoch 14 at step 4170.\n",
      "--- TRAINING COMPLETE ---\n",
      "Best model for 8-block architecture found at epoch 14 with PSNR: 46.5171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:2      eval psnr: 46.52     ssim: 0.9891\n",
      "best epoch: 14, psnr: 46.517124, ssim: 0.989099\n"
     ]
    }
   ],
   "source": [
    "logger_8_block.info(\"Instantiating Resumable Trainer with logs.\")\n",
    "trainer_8_block = CustomResumableTrainerLogger(\n",
    "    model=model_8_block,\n",
    "    args=args_8_block,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    logger=logger_8_block,  \n",
    ")\n",
    "\n",
    "\n",
    "logger_8_block.info(\"--- LAUNCHING TRAINING ---\")\n",
    "try:\n",
    "    trainer_8_block.train()\n",
    "    logger_8_block.info(\"--- TRAINING COMPLETE ---\")\n",
    "\n",
    "    final_best_epoch = trainer_8_block.best_epoch\n",
    "    final_best_psnr = trainer_8_block.best_metric\n",
    "    logger_8_block.info(\n",
    "        f\"Best model for 8-block architecture found at epoch {final_best_epoch} with PSNR: {final_best_psnr:.4f}\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    logger_8_block.error(f\"--- TRAINING FAILED ---: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd7035",
   "metadata": {},
   "source": [
    "# Gathering Final Model Metrics and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9800fe29-3f65-4c40-a5d1-abe2f8d8f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gathering Final Model Metrics and Parameters ---\n",
      "Successfully loaded best model from epoch 14\n",
      "\n",
      "Final PSNR (from checkpoint): 46.5171\n",
      "Total Trainable Parameters: 779,035\n",
      "\n",
      "Measuring inference time...\n",
      "Average Inference Time: 1.8959 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Gathering Final Model Metrics and Parameters ---\")\n",
    "\n",
    "# --- 1. Load the Best Model ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_path = config.finetune_dir / 'edsr_base_8_block/best_model_checkpoint.pt'\n",
    "model_8_block_final = EdsrModel(config_edsr_8block)\n",
    "\n",
    "# Load the state dictionary from checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_8_block_final.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_8_block_final.to(device)\n",
    "model_8_block_final.eval()\n",
    "\n",
    "print(f\"Successfully loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# --- 2. Get Final Metrics from Checkpoint ---\n",
    "final_psnr = checkpoint['best_metric']\n",
    "print(f\"\\nFinal PSNR (from checkpoint): {final_psnr:.4f}\")\n",
    "\n",
    "# --- 3. Calculate Total Trainable Parameters ---\n",
    "def count_parameters(m):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model_8_block_final)\n",
    "print(f\"Total Trainable Parameters: {total_params:,}\")\n",
    "\n",
    "# --- 4. Measure Inference Time ---\n",
    "# run inference on a single image multiple times to get a stable average.\n",
    "# Use a dummy tensor for this test.\n",
    "dummy_input = torch.randn(1, 3, 128, 128, device=device)\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "timings = []\n",
    "\n",
    "print(\"\\nMeasuring inference time...\")\n",
    "with torch.no_grad():\n",
    "    # Warm-up runs (to prime the GPU)\n",
    "    for _ in range(20):\n",
    "        _ = model_8_block_final(dummy_input)\n",
    "        \n",
    "    # Measurement runs\n",
    "    for _ in range(100):\n",
    "        starter.record()\n",
    "        _ = model_8_block_final(dummy_input)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize() # Wait for the GPU to finish\n",
    "        timings.append(starter.elapsed_time(ender))\n",
    "\n",
    "avg_inference_time_ms = sum(timings) / len(timings)\n",
    "print(f\"Average Inference Time: {avg_inference_time_ms:.4f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
